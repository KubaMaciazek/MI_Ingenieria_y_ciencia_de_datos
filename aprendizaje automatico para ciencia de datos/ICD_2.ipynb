{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3U9l3GZY8al"
      },
      "source": [
        "# Continious Optimization: Rastrigin Function\n",
        "\n",
        "In the previous activity, we solve some discrete (in particular, binary) problems. In this activity, we use several algorithms to solve a continuous problem, i.e., the solution is encoded as an array of float numbers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrGpx4F9Zt03"
      },
      "source": [
        "## Problem description\n",
        "The Rastrigin function is a non-convex function used as a performance test problem for optimization algorithms. It is a typical example of a non-linear multimodal function. Finding the minimum of this function is a fairly difficult problem due to its large search space and its large number of local minima.\n",
        "\n",
        "On an $n$-dimensional domain, the function to be **minimized** is:\n",
        "\n",
        "$f(\\mathbf{x}) = An + \\sum _{i=1}^{n}{x_{i}^{2}-A\\cos(2\\pi x_{i})}$\n",
        "\n",
        "where $A=10$ and $x_{i}\\in [-5.12,5.12]$. It has a global minimum at $\\mathbf {x} =\\mathbf {0}$  where $f(\\mathbf {x} )=0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMd6fupOcF8x"
      },
      "source": [
        "## Hill-Climbing algorithm for Rastrigin problem\n",
        "\n",
        "Our first algorithm will be a hill-climbing algorithm. This is a simple local search technique that starts with a random solution and iteratively improves it using a neighbourhood operator. Its pseudocode is the following:\n",
        "\n",
        "```\n",
        "sol = generate_initial_solution()\n",
        "while the stop criterion is not met do:\n",
        "  new_sol = generate_neighbour(sol)\n",
        "  if new_sol is better than sol:\n",
        "    sol = new_sol\n",
        "  endif\n",
        "endwhile\n",
        "return sol\n",
        "```\n",
        "\n",
        "For rastrigin:\n",
        "* The solutions will be a list of $n$ float numbers.\n",
        "* The initial solution will be randomly generated. For each value in the list, we generated a random value between -5.12 and 5.12.\n",
        "* For generating a neighbour, we change a single value using a normal distribution (with mean = 0 and standard deviation = $sigma$). $sigma$ will be a parameter of our algorithm.\n",
        "* We will **minimize** the rastrigin function.\n",
        "\n",
        "In the next cell, you can see the python code for this algorithm. Analyze the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8UdKtz-fpLC",
        "outputId": "66d4acb3-21df-42b2-9c44-5236317ad95f"
      },
      "outputs": [],
      "source": [
        "import random, math\n",
        "\n",
        "# ------------------------- FUNCTIONS ----------------------------------\n",
        "\n",
        "# Generate a random solution of M floats in the range [-5.12, 5.12]\n",
        "def random_solution(M):\n",
        "    sol = []\n",
        "    for i in range(M):\n",
        "        sol.append(random.uniform(-5.12, 5.12))\n",
        "    return sol\n",
        "\n",
        "# evaluate a solution (Rastrigin function)\n",
        "def evaluate_solution(s):\n",
        "    fitness = 10*len(s)\n",
        "    for x in s:\n",
        "        fitness += (x*x - 10*math.cos(2*math.pi*x))\n",
        "    return fitness\n",
        "\n",
        "# Generate a neighbour\n",
        "# - Modify on one position\n",
        "# - Add a value obtained from normal distribution (0, sigma)\n",
        "def get_neighbour(s, sigma):\n",
        "    pos = random.randint(0, len(s)-1)\n",
        "    factor = random.gauss(0, sigma)\n",
        "    neighbour = s[:]\n",
        "    neighbour[pos] += factor\n",
        "    if neighbour[pos] < -5.12: neighbour[pos] = -5.12\n",
        "    elif neighbour[pos] > 5.12: neighbour[pos] = 5.12\n",
        "    return neighbour\n",
        "\n",
        "# A simple HC\n",
        "def HC(cfg):\n",
        "    random.seed(cfg[\"seed\"])\n",
        "    # Generate an initial solution\n",
        "    best_sol = random_solution(cfg[\"dimension\"])\n",
        "    best_fitness = evaluate_solution(best_sol)\n",
        "    best_sol_iter = 0\n",
        "    for i in range(1, cfg[\"max_iterations\"]+1):\n",
        "        # Generate a neighbour\n",
        "        sol = get_neighbour(best_sol, cfg[\"sigma\"])\n",
        "        fitness = evaluate_solution(sol)\n",
        "        # Update the best solution if better\n",
        "        if fitness < best_fitness:\n",
        "            best_fitness = fitness\n",
        "            best_sol = sol\n",
        "            best_sol_iter = i\n",
        "    return best_sol, best_fitness, best_sol_iter\n",
        "\n",
        "# --------------------------- MAIN PROGRAM ----------------------------\n",
        "\n",
        "# Configuration\n",
        "cfg = {\n",
        "    \"seed\": 0, # seed for random numbers\n",
        "    \"dimension\": 10, # number of variables for rastrigin\n",
        "    \"max_iterations\": 5000, # maximum number of evaluations\n",
        "    \"sigma\": 0.7 # Parameter for the generation of neighbours (standard deviation for normal distribution)\n",
        "}\n",
        "\n",
        "# Run the algorithm 30 times (with different seeds) ...\n",
        "seeds = [50581, 61834, 22167, 64948, 71034, 80107, 78192, 7673, 56305, 64819, 55142, 37281, 69043, 52241, 78359, 40946, 47916, 69521, 37453, 63339, 85866, 35357, 73484, 37162, 86978, 93926, 98008, 38802, 3520, 1836]\n",
        "\n",
        "sols = []\n",
        "fits = []\n",
        "iters = []\n",
        "for seed in seeds:\n",
        "    cfg[\"seed\"] = seed\n",
        "    s, f, i = HC(cfg)\n",
        "    sols.append(s)\n",
        "    fits.append(f)\n",
        "    iters.append(i)\n",
        "    \n",
        "# ... and calculate statistics\n",
        "hits = 0\n",
        "avg_iter = 0\n",
        "avg_fit = 0\n",
        "avg_iter_total = 0\n",
        "for i in range(len(sols)):\n",
        "    avg_fit += fits[i]\n",
        "    avg_iter_total += iters[i]\n",
        "    if fits[i] < 0.01:\n",
        "        hits += 1\n",
        "        avg_iter += iters[i]\n",
        "print(f\"Configuration: {cfg}\")\n",
        "print(f\"Average fitness (average iterations): {avg_fit/len(sols)} ({avg_iter_total/len(sols)})\")\n",
        "print(f\"% hits: {hits} out of {len(sols)} ({hits*100/len(sols)}%)\")\n",
        "if hits > 0:\n",
        "    print(f\"Average number of evaluations to find the optimum: {avg_iter/hits}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acozm5uAgTM1"
      },
      "source": [
        "### Exercises\n",
        "1. Run the algorithm with different sigma values (from 0.1 to 1.0 with step 0.1), and complete the following table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBRh67lHg0Cw"
      },
      "source": [
        "Answer 1: (Modify the table)\n",
        "\n",
        "|  | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| % hits | | | | | | | 33.3 | | | |\n",
        "| Avg. Iters. | | | | | | | 4533.1 | | | |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlnSH5-WhaqF"
      },
      "source": [
        "2. Why do you think we obtain these results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjgNlILnhri1"
      },
      "source": [
        "Answer 2: (Write your answer here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jpDAu0thtf6"
      },
      "source": [
        "## VNS for Rastrigin problem\n",
        "\n",
        "VNS is a trajectory metaheuristic, i.e., it is a local search that includes some additional features to avoid local optima. Its code is quite similar to the previous one, but it uses several neighbour generation methods and it changes among them when the current method is not able to improve the solution. Its pseudocode is the following:\n",
        "\n",
        "```\n",
        "sol = generate_initial_solution()\n",
        "neighbourhood = 1\n",
        "while the stop criterion is not met do:\n",
        "  new_sol = generate_neighbour(sol, neighbourhood)\n",
        "  if new_sol is better than sol:\n",
        "    sol = new_sol\n",
        "    neighbourhood = 1\n",
        "  else:\n",
        "    neighbourhood += 1\n",
        "    if neighbourhood > MAX_NEIGHBOURHOOD:\n",
        "      neighbourhood = 1\n",
        "    endif\n",
        "  endif\n",
        "endwhile\n",
        "return sol\n",
        "```\n",
        "\n",
        "We will use 10 neighbourhoods. They will be the same used in HC but the different $sigma$ value, i.e., the first neighbourhood will use $sigma=0.1$, the second one will use $sigma=0.2$, and so on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWpiBUPjx54"
      },
      "source": [
        "### Exercises\n",
        "1. Copy the HC code and modify it to implement the VNS technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-zkKqoCj5tZ"
      },
      "outputs": [],
      "source": [
        "# VNS implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA-4D8uwj9Ak"
      },
      "source": [
        "2. Run the algorithm and copy the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI0CcxH2kf5I"
      },
      "source": [
        "Answer 2: (copy the results of the algorithm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E1QU2hhlAGD"
      },
      "source": [
        "## GA for Rastrigin problem\n",
        "\n",
        "Finally, we will also use the GA developed in our previous lesson to solve this problem. The main changes with respect to our ONEMAX/MTTP code are:\n",
        "* As fitness function (`evaluate_solution` function), you have to use the fitness function used by HC or VNS. NOTE: since VNS/HC are minimizing but GA is maximizing instead of `return fitness` use `return -fitness`.\n",
        "* As the method for generating a random solution, you have to use the `random_solution` function of HC or VNS code.\n",
        "* As mutation method, you can use the neighbour generation method used by HC. \n",
        "* Change the configuration of the technique (`dimension = 10`, `max_steps = 5000`) and add the $sigma$ parameter (`sigma = 0.7`).\n",
        "* Finally, modify the main program to obtain similar statistical values as in HC/VNS.\n",
        "* The rest of the code should not be changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXh3UcFCnRDF"
      },
      "source": [
        "### Exercises\n",
        "1. Implement a GA for solving Rastrigin problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHWb_aM5neUP"
      },
      "outputs": [],
      "source": [
        "# GA for Rastrigin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_pTN5cRnjng"
      },
      "source": [
        "2. Run the algorithm with different sigma values (from 0.1 to 1.0 with step 0.1), and complete the following table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JcEACornq71"
      },
      "source": [
        "Answer 2: (Modify the table)\n",
        "\n",
        "|  | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| % hits | | | | | | | | | | |\n",
        "| Avg. Iters. | | | | | | | | | | |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQWluAlrnv7b"
      },
      "source": [
        "3. (Optional) Instead of using the SPX crossover operator, use the BLX-$\\alpha$ one (with $\\alpha = 0.5$). The BLX-$\\alpha$ operator is the following:\n",
        "\n",
        "* Given two parents, p1 and p2, it generates a single child.\n",
        "* Select a random $\\gamma$ value $\\in$ [$-\\alpha$, $\\alpha$] ($\\alpha = 0.5$ for our experiments).\n",
        "* The child is generated as $\\gamma\\cdot$p1 + $(1-\\gamma)\\cdot$p2 (this formula should be applied to each value in the solution).\n",
        "\n",
        "Modify the code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYv129aTp5Iw"
      },
      "outputs": [],
      "source": [
        "# GA for Rastrigin (using BLX-alpha operator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-hCjTdrp_rs"
      },
      "source": [
        "4. (Optional) Run again the algorithm with different sigma values (from 0.1 to 1.0 with step 0.1), and complete the following table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjzsd1_4qOl9"
      },
      "source": [
        "Answer 4: (Modify the table)\n",
        "\n",
        "|  | 0.1 | 0.2 | 0.3 | 0.4 | 0.5 | 0.6 | 0.7 | 0.8 | 0.9 | 1.0 |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| % hits | | | | | | | | | | |\n",
        "| Avg. Iters. | | | | | | | | | | |"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ICD_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
